{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the Keras MNIST dataset:\n",
    "https://keras.io/api/datasets/mnist/\n",
    "\n",
    "The dataset contains 70,000 grayscale images of handwritten digits (0–9), each of size 28x28 pixels.\n",
    "\n",
    "Description of the returned structure:\n",
    "- Tuple of NumPy arrays: (x_train, y_train), (x_test, y_test).\n",
    "    - x_train: uint8 NumPy array of grayscale image data with shapes (60000, 28, 28), containing the training data. Pixel values range from 0 to 255.\n",
    "    - y_train: uint8 NumPy array of digit labels (integers in range 0-9) with shape (60000,) for the training data.\n",
    "    - x_test: uint8 NumPy array of grayscale image data with shapes (10000, 28, 28), containing the test data. Pixel values range from 0 to 255.\n",
    "    - y_test: uint8 NumPy array of digit labels (integers in range 0-9) with shape (10000,) for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data and assert size and shape.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "assert x_train.shape == (60000, 28, 28)\n",
    "assert x_test.shape == (10000, 28, 28)\n",
    "assert y_train.shape == (60000,)\n",
    "assert y_test.shape == (10000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to normalize our input data. This is required because we have values from 0-255 and we want values between 0-1.\n",
    "\n",
    "We use the value `255.0` here to return an array of decimals. Using the value `255` may be interpretted as an integer, and we would end up doing integer division. The resulting value would be `0` for values less than 255 and `1` for values equallying 255.\n",
    "\n",
    "As an aside, we only have a single \"color\" here because the MNIST dataset is greyscale. The MNIST dataset is effectively the \"hello world\" of machine learning. If we were working in full RGB color, we would have three input signals per pixel. This bloats the number of inputs per instance from 784 to 2352. This is avoided because it introduces complexity and increases training time. We can work with more complicated datasets later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can label our data.\n",
    "\n",
    "Because we are working with output values from 0 to 9, we have 10 total potential outcomes. We can use the utility `to_categorical` method for binary classification. In other words, we're saying we have two choices if a given input matrix matches each of the 10 labeled outcomes -- `true` or `false`.\n",
    "\n",
    "Read More: https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical\n",
    "\n",
    "Using a sample from this page:\n",
    "```\n",
    "a = keras.utils.to_categorical([0, 1, 2, 3], num_classes=4)\n",
    "print(a)\n",
    "```\n",
    "\n",
    "Result:\n",
    "```\n",
    "[[1, 0, 0, 0,]\n",
    " [0, 1, 0, 0,]\n",
    " [0, 0, 1, 0,]\n",
    " [0, 0, 0, 1,]]\n",
    "```\n",
    "\n",
    "The result array contains 4 entries to match the `num_classes` parameter. The `to_categorical()` call counts from 0 to 3 and labels the input based on if the entry value (indexes in this case) matches the category value (incrementing counter value in this case).\n",
    "\n",
    "This type of encoding is called [one-hot encoding](https://www.geeksforgeeks.org/ml-one-hot-encoding/). It's less of a risk in this simple example, but in more complex models, order matters. If we left our categories as 0 through 9, we run the risk of biasing toward larger (or smaller) outputs based on the order the model sees its training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (60000, 10), y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train = to_categorical(y_train, 10) \n",
    "y_test = to_categorical(y_test, 10) \n",
    "\n",
    "print(f\"y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build the neural network.\n",
    "\n",
    "We use `Sequential` here because we expect unidirectional data flow (or in other words, no recursion, no branching, etc). Here's a description of the network's three layers:\n",
    "1. The first layer matches the shape of our input. In this case, 28 x 28 matrix of decimal values ranging from 0 to 1.\n",
    "2. The second layer is a dense hidden layer of 128 nodes -- activated by the ReLU function. \n",
    "   1. Why 128? Choosing the right hidden layer size (or count) can be explored in future experiments. Just note that more neurons will generally take longer to train but **MAY** lead to better outputs.\n",
    "   2. Why ReLU? ReLU (or rectified linear unit) is a non-linear activation function that returns 0 for negative values. It returns N for all N >= 0. It's generally used in binary on-off classification problems. We can look non-binary classification problems in future experiements.\n",
    "   3. Why only one hidden layer? Because this is a relatively simple problem. Imagine each layer learning a combination of factors from the previous layer. In a photograph classification problem (e.g. is this full-color image a dog?), we'd start with a hidden layer of the colors beginning to recognize lines and shapes. We could add another hidden layer to turn those lines and shapes into textures. Those textures could feed an additional hidden layer, which could recognize fur, eyes, paws, tails, etc. With enough of those structures in the right size, shape, and color, the final output will give a percent certainty that the given image is of a dog.\n",
    "   4. Why is it dense? Because each input is connected to each output, and each output is connected to each input. There are neural networks where we don't want each layer densely connected. Those will be seen in later experiments.\n",
    "3. The third layer is the output of 10 values. These are our 10 potential categories of 0 through 9.\n",
    "   1. Why softmax? Softmax sums our 10 outputs and turns them into percentages of this summed value. Each number represents the \"certainty\" the model has for the given input matching the given output. This provides the relative percent \"chance\" of a given input mapping to the output categories.\n",
    "   \n",
    "For our scenario, we could add 100 hidden layers if we wanted. It would increase the time it takes to train for no real gain (or potentially even a loss). Rightsizing the size and shape of neural network requires experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(28, 28)),\n",
    "    Flatten(),    \n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to train and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8795 - loss: 0.4295\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9632 - loss: 0.1238\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9753 - loss: 0.0822\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9817 - loss: 0.0586\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9866 - loss: 0.0442\n",
      "313/313 - 0s - 1ms/step - accuracy: 0.9764 - loss: 0.0736\n",
      "Test accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This states that our model has reached a 98.6% accuracy for unseen test data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
